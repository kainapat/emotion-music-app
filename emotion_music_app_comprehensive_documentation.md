# ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Emotion Music App

## ‡∏ö‡∏ó‡∏ô‡∏≥

‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Emotion Music App ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ Machine Learning ‡πÅ‡∏•‡∏∞ Natural Language Processing ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏•‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÅ‡∏ö‡∏ö‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏≠‡∏Ñ‡∏ó‡∏µ‡∏ü

## ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å

### 1. ‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÄ‡∏û‡∏•‡∏á

#### ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
- **‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏±‡∏Å**: ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• BART (facebook/bart-large-mnli) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÅ‡∏ö‡∏ö zero-shot
- **8 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå**:
  - ‡πÄ‡∏®‡∏£‡πâ‡∏≤ (sad) - ‡∏£‡∏ß‡∏° ‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à, ‡∏´‡∏°‡πà‡∏ô, ‡∏´‡∏°‡∏≠‡∏á, ‡∏´‡∏î‡∏´‡∏π‡πà, ‡∏ã‡∏∂‡∏°, ‡∏£‡πâ‡∏≠‡∏á‡πÑ‡∏´‡πâ, ‡∏ó‡∏∏‡∏Å‡∏Ç‡πå, ‡∏ô‡πâ‡∏≠‡∏¢‡πÉ‡∏à, ‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á
  - ‡πÄ‡∏´‡∏á‡∏≤ (lonely) - ‡∏£‡∏ß‡∏° ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏î‡∏≤‡∏¢, ‡∏ß‡πâ‡∏≤‡πÄ‡∏´‡∏ß‡πà
  - ‡∏´‡∏ß‡∏±‡∏á (hope) - ‡∏£‡∏ß‡∏° ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ß‡∏±‡∏á, ‡∏°‡∏µ‡∏´‡∏ß‡∏±‡∏á, ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à, ‡∏™‡∏π‡πâ, ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°
  - ‡∏™‡∏∏‡∏Ç (happy) - ‡∏£‡∏ß‡∏° ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ, ‡∏î‡∏µ‡πÉ‡∏à, ‡∏£‡πà‡∏≤‡πÄ‡∏£‡∏¥‡∏á, ‡∏™‡∏î‡πÉ‡∏™, ‡∏™‡∏ô‡∏∏‡∏Å, ‡∏¢‡∏¥‡πâ‡∏°, ‡πÄ‡∏ö‡∏¥‡∏Å‡∏ö‡∏≤‡∏ô
  - ‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô (excited) - ‡∏£‡∏ß‡∏° ‡πÄ‡∏£‡πâ‡∏≤‡πÉ‡∏à, ‡∏û‡∏µ‡∏Ñ, ‡∏°‡∏±‡∏ô, ‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß, ‡∏Æ‡∏∂‡∏Å‡πÄ‡∏´‡∏¥‡∏°
  - ‡∏™‡∏á‡∏ö (calm) - ‡∏£‡∏ß‡∏° ‡πÄ‡∏¢‡∏∑‡∏≠‡∏Å‡πÄ‡∏¢‡πá‡∏ô, ‡∏ô‡∏¥‡πà‡∏á, ‡πÉ‡∏à‡πÄ‡∏¢‡πá‡∏ô, ‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢, ‡∏ä‡∏¥‡∏•
  - ‡πÇ‡∏Å‡∏£‡∏ò (angry) - ‡∏£‡∏ß‡∏° ‡πÇ‡∏°‡πÇ‡∏´, ‡πÄ‡∏î‡∏∑‡∏≠‡∏î, ‡πÅ‡∏Ñ‡πâ‡∏ô, ‡πÄ‡∏Ñ‡∏∑‡∏≠‡∏á
  - ‡πÄ‡∏â‡∏¢ (neutral) - ‡∏£‡∏ß‡∏° ‡∏õ‡∏Å‡∏ï‡∏¥, ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤

#### ‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡∏£‡∏≠‡∏á
- **‡∏û‡∏à‡∏ô‡∏≤‡∏ô‡∏∏‡∏Å‡∏£‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢**: ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Å‡∏ß‡πà‡∏≤ 50 ‡∏Ñ‡∏≥‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏™‡∏≠‡∏á‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á
- **‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥**: ‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡∏±‡∏ö‡∏Å‡∏±‡∏ô
- **‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à**: threshold = 0.55 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å

#### ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤
- **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á**: ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÅ‡∏•‡∏∞‡∏ú‡∏™‡∏°‡∏Å‡∏±‡∏ô
- **‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏≥‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥**: ‡πÉ‡∏ä‡πâ PyThaiNLP ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡∏∞ NLTK ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©

### 2. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á

#### ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞
- **‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ó‡∏¢**: ‡∏≠‡∏¥‡∏ô‡πÇ‡∏ó‡∏£, ‡∏ó‡πà‡∏≠‡∏ô, ‡∏Ñ‡∏≠‡∏£‡∏±‡∏™, ‡∏ö‡∏£‡∏¥‡∏î‡∏à‡πå, ‡πÄ‡∏≠‡∏≤‡∏ó‡πå‡πÇ‡∏ó‡∏£
- **‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©**: intro, verse, chorus, bridge, outro
- **‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡∏£‡∏≠‡∏á**: ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß

#### ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
```python
def _clean_text(s: str) -> str:
    s = re.sub(r'https?://\S+', ' ', s)     # ‡∏•‡∏ö URL
    s = re.sub(r'#[\w‡∏Å-‡πô]+', ' ', s)        # ‡∏•‡∏ö hashtags
    s = re.sub(r'[^\S\r\n]+', ' ', s)       # ‡∏¢‡πà‡∏≠‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á
    s = re.sub(r'[^\x00-\x7F‡∏Å-‡πô\r\n ]', ' ', s)  # ‡∏•‡∏ö emoji/‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©
    return s.strip()
```

#### ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏≥‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
```python
def auto_tokenize(text: str) -> str:
    # ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
    parts = re.split(r'([A-Za-z]+(?:\s+[A-Za-z]+)*)', line)
    
    for part in parts:
        if re.match(r'^[A-Za-z\s]+$', part):
            tokens = nltk.word_tokenize(part)  # ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        else:
            tokens = thai_tokenize(part)  # ‡πÑ‡∏ó‡∏¢
```

### 3. ‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á

#### ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
- **‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏•‡∏π‡∏Å‡∏®‡∏£**: "‡πÄ‡∏®‡∏£‡πâ‡∏≤ ‚Üí ‡∏´‡∏ß‡∏±‡∏á" ‡∏´‡∏£‡∏∑‡∏≠ "sad ‚Üí hope"
- **‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢**: "‡πÄ‡∏û‡∏•‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏®‡∏£‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ß‡∏±‡∏á"
- **‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©**: "song that starts sad and becomes happy"
- **‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß**: "‡πÄ‡∏®‡∏£‡πâ‡∏≤", "neutral", "‡∏™‡∏∏‡∏Ç"
- **‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ñ‡∏á‡∏ó‡∏µ‡πà**: "‡πÄ‡∏û‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå neutral ‡∏ï‡∏•‡∏≠‡∏î‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏û‡∏•‡∏á"

#### ‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà
```python
def calculate_match_score(query_emotions, song_emotions):
    # ‡πÉ‡∏ä‡πâ Longest Common Subsequence (LCS) algorithm
    n, m = len(query_emotions), len(song_emotions)
    dp = [[0] * (m + 1) for _ in range(n + 1)]
    
    for i in range(1, n + 1):
        for j in range(1, m + 1):
            if query_emotions[i-1] == song_emotions[j-1]:
                dp[i][j] = dp[i-1][j-1] + 1
            else:
                dp[i][j] = max(dp[i-1][j], dp[i][j-1])
    
    lcs_length = dp[n][m]
    return min(lcs_length / len(query_emotions), 1.0)
```

#### ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡πÅ‡∏ö‡∏ö‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô
```python
def soft_subseq_match(target, seq):
    # ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡πÅ‡∏ö‡∏ö soft subsequence
    i = 0
    for s in seq:
        if i < len(target) and s == target[i]:
            i += 1
    return i == len(target)
```

#### ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢
```python
# vectorstore.py
import faiss
from sentence_transformers import SentenceTransformer

embedder = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
index = faiss.IndexFlatL2(384)

def search_query(query, top_k=5):
    vec = embedder.encode([query])
    D, I = index.search(np.array(vec, dtype="float32"), top_k)
    results = [metadata[i] for i in I[0]]
    return results
```

### 4. ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏≠‡∏Ñ‡∏ó‡∏µ‡∏ü

#### ‡∏Å‡∏£‡∏≤‡∏ü Plotly
```python
def plot_interactive_trajectory(emotions, song_name):
    df = pd.DataFrame({"step": range(len(emotions)), "emotion": emotions})
    fig = px.line(
        df, x="step", y="emotion",
        title=f"Emotion Trajectory: {song_name}",
        markers=True,
        labels={"step": "Step", "emotion": "Emotion"}
    )
    return fig.to_html(full_html=False)
```

#### ‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏µ‡πÅ‡∏•‡∏∞‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô
- **‡πÄ‡∏®‡∏£‡πâ‡∏≤ (SAD)**: ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡∏ü‡πâ‡∏≤ + ‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô üíô
- **‡πÄ‡∏´‡∏á‡∏≤ (LONELY)**: ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡∏°‡πà‡∏ß‡∏á + ‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô üíú
- **‡∏´‡∏ß‡∏±‡∏á (HOPE)**: ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß + ‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô üíö
- **‡∏™‡∏∏‡∏Ç (HAPPY)**: ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á + ‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô üíõ
- **‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô (EXCITED)**: ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡πÅ‡∏î‡∏á + ‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô ‚ù§Ô∏è
- **‡∏™‡∏á‡∏ö (CALM)**: ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡∏Ñ‡∏£‡∏≤‡∏° + ‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô üîµ
- **‡πÇ‡∏Å‡∏£‡∏ò (ANGRY)**: ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡∏™‡πâ‡∏° + ‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô üß°
- **‡πÄ‡∏â‡∏¢ (NEUTRAL)**: ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡πÄ‡∏ó‡∏≤ + ‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô ‚ö™

#### ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°
```python
def calculate_overall_emotion(emotions):
    # ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
    emotion_counts = {}
    for emotion in emotions:
        emotion = emotion.lower() if emotion else "unknown"
        emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
    
    # ‡∏´‡∏≤‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    most_common_emotion = max(emotion_counts.items(), key=lambda x: x[1])
    
    # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏°‡∏µ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 50% ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ô‡∏±‡πâ‡∏ô
    total_emotions = len(emotions)
    if most_common_emotion[1] / total_emotions > 0.5:
        return most_common_emotion[0]
    
    return most_common_emotion[0]
```

## ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•

### 1. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏û‡∏•‡∏á‡πÉ‡∏´‡∏°‡πà

```python
# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
youtube_link = request.form["youtube"]
lyrics = request.form["lyrics"]

# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏°‡∏ï‡∏≤‡∏à‡∏≤‡∏Å YouTube API
video_id = extract_video_id(yt_link)
meta = fetch_youtube_metadata(video_id)

# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ã‡πâ‡∏≥
existing = db_query("SELECT id FROM songs WHERE youtube_link=?", (yt_link,), fetch=True)
if existing:
    return render_template("index.html", songs=songs, error="‚ö†Ô∏è ‡πÄ‡∏û‡∏•‡∏á‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏•‡πâ‡∏ß ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ")

# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡πÄ‡∏£‡∏¥‡πà‡∏° transaction
cur.execute("BEGIN TRANSACTION")

# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5: ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ
segments = preprocess_lyrics(lyrics)

# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 6: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
emotions = []
for i, seg in enumerate(segments):
    e = detect_emotion(seg)
    emotions.append(e)
    cur.execute("""
        INSERT INTO segments (song_id,segment_order,text,emotion) 
        VALUES (?,?,?,?)""", (song_id, i, seg, e))

# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 7: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
trajectory_html = plot_interactive_trajectory(emotions, meta.get("title"))
cur.execute("UPDATE songs SET graph_html=? WHERE id=?", 
          (trajectory_html, song_id))

# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 8: commit transaction
conn.commit()
```

### 2. ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏û‡∏•‡∏á

```python
# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÅ‡∏õ‡∏•‡∏á query ‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
raw = request.form.get("query", "")
q_tokens = parse_thai_emotion_query(raw)  # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå

# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏î‡∏∂‡∏á‡πÄ‡∏û‡∏•‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡∏∞ segments
all_songs = db_query("SELECT id,title,view_count,like_count,upload_date,graph_html FROM songs", fetch=True)

# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
for s in all_songs:
    segs = db_query("SELECT emotion FROM segments WHERE song_id=? ORDER BY segment_order", (s[0],), fetch=True)
    song_seq = [_canonize(x[0]) for x in segs]

    # ‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏ö‡∏ö soft-subsequence ‡∏Å‡πá‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤ match
    if soft_subseq_match(q_tokens, song_seq):
        score = calculate_match_score(q_tokens, song_seq)
        scored_songs.append((score, s))

# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
scored_songs.sort(key=lambda x: (-x[0], -x[1][2]))
songs = [s for _, s in scored_songs]
```

### 3. ‡∏Å‡∏≤‡∏£‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏•‡∏á

```python
# ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏•‡∏á‡∏´‡∏•‡∏±‡∏Å
song = db_query("""SELECT id,title,youtube_link,upload_date,view_count,like_count,graph_html,lyrics
                   FROM songs WHERE id=?""", (song_id,), fetch=True)

# ‡∏î‡∏∂‡∏á segments ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö
segments = db_query("""SELECT segment_order,text,emotion
                       FROM segments WHERE song_id=? ORDER BY segment_order""",
                    (song_id,), fetch=True)

# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°
emotions = [seg[2] for seg in segments if seg[2]]
overall_emotion = calculate_overall_emotion(emotions)
emotion_explanation = get_emotion_explanation(overall_emotion, emotions)
```

## ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ

### 1. Machine Learning ‡πÅ‡∏•‡∏∞ NLP

#### Transformers Library
```python
# emotion_model.py
from transformers import pipeline

# ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• BART ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
ZS_MODEL = "facebook/bart-large-mnli"
_zs = pipeline("zero-shot-classification", model=ZS_MODEL)

def detect_emotion(text: str, threshold: float = 0.55, multi_label: bool = False) -> str:
    res = _zs(text, candidate_labels=CANDIDATE_LABELS, multi_label=multi_label)
    
    if multi_label:
        picked = [lbl for lbl, sc in zip(res["labels"], res["scores"]) if sc >= threshold]
        if picked:
            return picked[0]  # Return English label directly
    else:
        lbl, sc = res["labels"][0], res["scores"][0]
        if sc >= threshold:
            return lbl  # Return English label directly
    
    # Get Thai emotion and convert back to English
    thai_emotion = _lexicon_fallback(text)
    return THAI_TO_ENG.get(thai_emotion, "neutral")
```

#### ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
```python
# nlp_utils.py
from pythainlp.tokenize import word_tokenize as thai_tokenize
import nltk

def auto_tokenize(text: str) -> str:
    if not text:
        return ""
    
    lines = text.split('\n')
    tokenized_lines = []
    
    for line in lines:
        if not line.strip():
            tokenized_lines.append('')
            continue
            
        # ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        parts = re.split(r'([A-Za-z]+(?:\s+[A-Za-z]+)*)', line)
        tokenized_parts = []
        
        for part in parts:
            if not part.strip():
                continue
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
            if re.match(r'^[A-Za-z\s]+$', part):
                tokens = nltk.word_tokenize(part)
                tokenized_parts.append(' '.join(tokens))
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
            else:
                tokens = thai_tokenize(part)
                tokenized_parts.append(' '.join(tokens))
                
        tokenized_lines.append(' '.join(tokenized_parts))
    
    return '\n'.join(tokenized_lines)
```

### 2. ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ YouTube API

```python
# youtube_utils.py
from googleapiclient.discovery import build
import re
import os
from dotenv import load_dotenv

load_dotenv()
API_KEY = os.getenv("YOUTUBE_API_KEY")

def fetch_youtube_metadata(video_id):
    youtube = build("youtube", "v3", developerKey=API_KEY)
    request = youtube.videos().list(
        part="snippet,statistics",
        id=video_id
    )
    response = request.execute()
    
    if not response["items"]:
        return None

    item = response["items"][0]
    snippet = item["snippet"]
    stats = item["statistics"]

    return {
        "title": snippet.get("title"),
        "description": snippet.get("description"),
        "tags": snippet.get("tags", []),
        "upload_date": snippet.get("publishedAt"),
        "view_count": stats.get("viewCount"),
        "like_count": stats.get("likeCount"),
    }

def extract_video_id(url: str):
    pattern = r"(?:v=|youtu\.be/)([a-zA-Z0-9_-]{11})"
    match = re.search(pattern, url)
    return match.group(1) if match else None
```

### 3. ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå

```python
# vectorstore.py
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

embedder = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á index FAISS
dimension = 384
index = faiss.IndexFlatL2(dimension)

# mapping (id ‚Üí song/segment)
metadata = []

def add_segments_to_index(song_id, segments):
    vectors = embedder.encode(segments)
    index.add(np.array(vectors, dtype="float32"))
    for i in range(len(segments)):
        metadata.append((song_id, i))

def search_query(query, top_k=5):
    vec = embedder.encode([query])
    D, I = index.search(np.array(vec, dtype="float32"), top_k)
    results = [metadata[i] for i in I[0]]
    return results
```

### 4. ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå

```python
# analysis.py
import plotly.express as px
import pandas as pd

def build_trajectory(segments, emotions):
    return [(i, e) for i, e in enumerate(emotions)]

def plot_interactive_trajectory(emotions, song_name):
    df = pd.DataFrame({"step": range(len(emotions)), "emotion": emotions})
    fig = px.line(
        df, x="step", y="emotion",
        title=f"Emotion Trajectory: {song_name}",
        markers=True,
        labels={
            "step": "Step",  # X-axis label in English
            "emotion": "Emotion"  # Y-axis label in English
        }
    )
    return fig.to_html(full_html=False)  # Return HTML string
```

## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡πÅ‡∏•‡∏∞‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå

### 1. ‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©

```python
# emotion_model.py
THAI_TO_ENG = {
    # ‡πÄ‡∏®‡∏£‡πâ‡∏≤
    "‡πÄ‡∏®‡∏£‡πâ‡∏≤": "sad", "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à": "sad", "‡∏´‡∏°‡πà‡∏ô": "sad", "‡∏´‡∏°‡∏≠‡∏á": "sad", 
    "‡∏´‡∏î‡∏´‡∏π‡πà": "sad", "‡∏ã‡∏∂‡∏°": "sad", "‡∏£‡πâ‡∏≠‡∏á‡πÑ‡∏´‡πâ": "sad", "‡∏ô‡πâ‡∏≥‡∏ï‡∏≤": "sad",
    "‡∏ó‡∏∏‡∏Å‡∏Ç‡πå": "sad", "‡∏ô‡πâ‡∏≠‡∏¢‡πÉ‡∏à": "sad", "‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á": "sad",
    
    # ‡πÄ‡∏´‡∏á‡∏≤
    "‡πÄ‡∏´‡∏á‡∏≤": "lonely", "‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏î‡∏≤‡∏¢": "lonely", "‡∏ß‡πâ‡∏≤‡πÄ‡∏´‡∏ß‡πà": "lonely",
    
    # ‡∏´‡∏ß‡∏±‡∏á
    "‡∏´‡∏ß‡∏±‡∏á": "hope", "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ß‡∏±‡∏á": "hope", "‡∏°‡∏µ‡∏´‡∏ß‡∏±‡∏á": "hope", 
    "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à": "hope", "‡∏™‡∏π‡πâ": "hope", "‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°": "hope",
    
    # ‡∏™‡∏∏‡∏Ç
    "‡∏™‡∏∏‡∏Ç": "happy", "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ": "happy", "‡∏î‡∏µ‡πÉ‡∏à": "happy", 
    "‡∏£‡πà‡∏≤‡πÄ‡∏£‡∏¥‡∏á": "happy", "‡∏™‡∏î‡πÉ‡∏™": "happy", "‡∏™‡∏ô‡∏∏‡∏Å": "happy",
    "‡πÅ‡∏Æ‡∏õ‡∏õ‡∏µ‡πâ": "happy", "‡∏¢‡∏¥‡πâ‡∏°": "happy", "‡πÄ‡∏ö‡∏¥‡∏Å‡∏ö‡∏≤‡∏ô": "happy",
    
    # ‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô
    "‡πÄ‡∏£‡πâ‡∏≤‡πÉ‡∏à": "excited", "‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô": "excited", "‡∏û‡∏µ‡∏Ñ": "excited",
    "‡∏°‡∏±‡∏ô": "excited", "‡πÄ‡∏õ‡∏£‡∏µ‡πâ‡∏¢‡∏ß": "excited", "‡∏Æ‡∏∂‡∏Å‡πÄ‡∏´‡∏¥‡∏°": "excited",
    
    # ‡∏™‡∏á‡∏ö
    "‡∏™‡∏á‡∏ö": "calm", "‡πÄ‡∏¢‡∏∑‡∏≠‡∏Å‡πÄ‡∏¢‡πá‡∏ô": "calm", "‡∏ô‡∏¥‡πà‡∏á": "calm",
    "‡πÉ‡∏à‡πÄ‡∏¢‡πá‡∏ô": "calm", "‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢": "calm", "‡∏ä‡∏¥‡∏•": "calm",
    
    # ‡πÇ‡∏Å‡∏£‡∏ò
    "‡πÇ‡∏Å‡∏£‡∏ò": "angry", "‡πÇ‡∏°‡πÇ‡∏´": "angry", "‡πÄ‡∏î‡∏∑‡∏≠‡∏î": "angry",
    "‡πÅ‡∏Ñ‡πâ‡∏ô": "angry", "‡πÇ‡∏Å‡∏£‡∏ò‡∏≤": "angry", "‡πÄ‡∏Ñ‡∏∑‡∏≠‡∏á": "angry",
    
    # ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á
    "‡∏õ‡∏Å‡∏ï‡∏¥": "neutral", "‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤": "neutral", "‡πÄ‡∏â‡∏¢": "neutral"
}

# reverse mapping ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©-‡πÑ‡∏ó‡∏¢
ENG_TO_THAI = {
    "sad": "‡πÄ‡∏®‡∏£‡πâ‡∏≤",
    "lonely": "‡πÄ‡∏´‡∏á‡∏≤",
    "hope": "‡∏´‡∏ß‡∏±‡∏á",
    "happy": "‡∏™‡∏∏‡∏Ç",
    "excited": "‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô",
    "calm": "‡∏™‡∏á‡∏ö",
    "angry": "‡πÇ‡∏Å‡∏£‡∏ò",
    "neutral": "‡πÄ‡∏â‡∏¢"
}
```

### 2. ‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå

```python
def calculate_match_score(query_emotions, song_emotions):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á query ‡∏Å‡∏±‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏•‡∏á
    Returns: float (0.0 - 1.0)
    """
    if not query_emotions or not song_emotions:
        return 0.0
    
    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    def normalize_emotion(e):
        if e in THAI_TO_ENG:
            return THAI_TO_ENG[e]
        return e.lower() if e else e
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏ù‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
    query_emotions = [normalize_emotion(e) for e in query_emotions]
    song_emotions = [normalize_emotion(e) for e in song_emotions]
    
    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ñ‡∏á‡∏ó‡∏µ‡πà: ‡∏ñ‡πâ‡∏≤ query ‡∏°‡∏µ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    if len(set(query_emotions)) == 1:
        target_emotion = query_emotions[0]
        emotion_count = sum(1 for s in song_emotions if s == target_emotion)
        if emotion_count == 0:
            return 0.0
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
        return min(emotion_count / len(song_emotions), 1.0)
    
    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏õ‡∏Å‡∏ï‡∏¥: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
    # ‡πÉ‡∏ä‡πâ Longest Common Subsequence (LCS) algorithm
    n, m = len(query_emotions), len(song_emotions)
    dp = [[0] * (m + 1) for _ in range(n + 1)]
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì LCS
    for i in range(1, n + 1):
        for j in range(1, m + 1):
            if query_emotions[i-1] == song_emotions[j-1]:
                dp[i][j] = dp[i-1][j-1] + 1
            else:
                dp[i][j] = max(dp[i-1][j], dp[i][j-1])
    
    lcs_length = dp[n][m]
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á LCS ‡πÅ‡∏•‡∏∞‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
    if lcs_length == 0:
        return 0.0
    
    # Base score: ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á LCS ‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á query
    base_score = lcs_length / len(query_emotions)
    
    # Position bonus: ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ñ‡πâ‡∏≤‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    position_bonus = 0.0
    query_idx = 0
    for song_emotion in song_emotions:
        if query_idx < len(query_emotions) and song_emotion == query_emotions[query_idx]:
            query_idx += 1
            position_bonus += 0.1  # bonus ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
    
    # Normalize position bonus
    position_bonus = min(position_bonus, 0.3)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î bonus ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 30%
    
    final_score = min(base_score + position_bonus, 1.0)
    return final_score
```

### 3. ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏≠‡∏Ñ‡∏ó‡∏µ‡∏ü

```python
# analysis.py
import plotly.express as px
import pandas as pd

def plot_interactive_trajectory(emotions, song_name):
    df = pd.DataFrame({"step": range(len(emotions)), "emotion": emotions})
    fig = px.line(
        df, x="step", y="emotion",
        title=f"Emotion Trajectory: {song_name}",
        markers=True,
        labels={
            "step": "Step",  # X-axis label in English
            "emotion": "Emotion"  # Y-axis label in English
        }
    )
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
    fig.update_layout(
        xaxis_title="Step",
        yaxis_title="Emotion",
        hovermode='closest',
        showlegend=False
    )
    
    return fig.to_html(full_html=False)  # Return HTML string
```

### 4. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Query ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô

```python
def parse_thai_emotion_query(q: str):
    """
    ‡∏£‡∏±‡∏ö query ‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‚Üí ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
    """
    if not q:
        return []

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏•‡∏π‡∏Å‡∏®‡∏£
    if "‚Üí" in q or "->" in q:
        q = q.replace("->", "‚Üí")
        parts = [p.strip() for p in q.split("‚Üí") if p.strip()]
        return [_canonize(p) for p in parts]

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡∏Å‡πà‡∏≠‡∏ô
    constant_patterns = [
        r"(‡∏Ñ‡∏á‡∏ó‡∏µ‡πà|‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á|‡∏ï‡∏•‡∏≠‡∏î‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏û‡∏•‡∏á|throughout|consistent|stable)",
        r"(‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°|‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏û‡∏•‡∏á|all the way|same emotion)"
    ]
    
    for pattern in constant_patterns:
        if re.search(pattern, q, re.IGNORECASE):
            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á
            tokens = word_tokenize(q)
            for token in tokens:
                emotion = _canonize(token)
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Ñ‡∏≥‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
                if emotion and emotion != " " and emotion != "" and emotion not in ["‡πÄ‡∏û‡∏•‡∏á", "‡∏ó‡∏µ‡πà", "‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå", "‡∏´‡∏≤", "‡∏°‡∏µ", "‡∏ï‡∏•‡∏≠‡∏î", "‡∏ó‡∏±‡πâ‡∏á", "‡πÑ‡∏°‡πà", "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á", "‡∏Ñ‡∏á‡∏ó‡∏µ‡πà"]:
                    # ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô 3 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á
                    return [emotion] * 3
    
    return _parse_complex_emotion_query(q)
```

## ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å

### 1. YouTube Data API v3

#### ‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏°‡∏ï‡∏≤
```python
from googleapiclient.discovery import build
import os
from dotenv import load_dotenv

load_dotenv()
API_KEY = os.getenv("YOUTUBE_API_KEY")

def fetch_youtube_metadata(video_id):
    youtube = build("youtube", "v3", developerKey=API_KEY)
    request = youtube.videos().list(
        part="snippet,statistics",
        id=video_id
    )
    response = request.execute()
    
    if not response["items"]:
        return None

    item = response["items"][0]
    snippet = item["snippet"]
    stats = item["statistics"]

    return {
        "title": snippet.get("title"),
        "description": snippet.get("description"),
        "tags": snippet.get("tags", []),
        "upload_date": snippet.get("publishedAt"),
        "view_count": stats.get("viewCount"),
        "like_count": stats.get("likeCount"),
    }
```

#### ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏•‡∏¥‡∏á‡∏Å‡πå
```python
def extract_video_id(url: str):
    pattern = r"(?:v=|youtu\.be/)([a-zA-Z0-9_-]{11})"
    match = re.search(pattern, url)
    return match.group(1) if match else None
```

### 2. Hugging Face Transformers

#### ‡πÇ‡∏°‡πÄ‡∏î‡∏• BART
```python
from transformers import pipeline

# ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà stable
ZS_MODEL = "facebook/bart-large-mnli"
_zs = pipeline("zero-shot-classification", model=ZS_MODEL)

CANDIDATE_LABELS = ["sad", "lonely", "hope", "happy", "excited", "calm", "angry", "neutral"]

def detect_emotion(text: str, threshold: float = 0.55, multi_label: bool = False) -> str:
    if not text.strip():
        return "neutral" 
    
    try:
        res = _zs(text, candidate_labels=CANDIDATE_LABELS, multi_label=multi_label)
        
        if multi_label:
            picked = [lbl for lbl, sc in zip(res["labels"], res["scores"]) if sc >= threshold]
            if picked:
                return picked[0]  # Return English label directly
        else:
            lbl, sc = res["labels"][0], res["scores"][0]
            if sc >= threshold:
                return lbl  # Return English label directly
        
        # Get Thai emotion and convert back to English
        thai_emotion = _lexicon_fallback(text)
        return THAI_TO_ENG.get(thai_emotion, "neutral")
        
    except Exception:
        thai_emotion = _lexicon_fallback(text)
        return THAI_TO_ENG.get(thai_emotion, "neutral")
```

#### Sentence Transformers
```python
from sentence_transformers import SentenceTransformer

embedder = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå
vectors = embedder.encode(segments)
```

## ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ

### 1. Web Routes ‡∏´‡∏•‡∏±‡∏Å

```python
from flask import Flask, render_template, request, jsonify

app = Flask(__name__)

# ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏û‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏î‡∏π‡πÄ‡∏û‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
@app.route("/", methods=["GET","POST"])
def index():
    # ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏û‡∏•‡∏á‡πÉ‡∏´‡∏°‡πà
    
# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏û‡∏•‡∏á
@app.route("/search", methods=["GET","POST"])
def search():
    # ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
    
# ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏•‡∏á
@app.route("/song/<int:song_id>")
def song_detail(song_id):
    # ‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
    
# ‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
@app.route("/song/<int:song_id>/refresh")
def refresh_song(song_id):
    # ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏´‡∏°‡πà
    
# ‡∏£‡∏µ‡∏ö‡∏¥‡∏•‡∏î‡πå‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
@app.route("/song/<int:song_id>/rebuild", methods=["POST"])
def rebuild_song(song_id):
    # ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    
# ‡∏•‡∏ö‡πÄ‡∏û‡∏•‡∏á
@app.route("/song/<int:song_id>/delete", methods=["POST"])
def delete_song(song_id):
    # ‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    
# ‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÄ‡∏û‡∏•‡∏á
@app.route("/explore")
def explore():
    # ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
    
# ‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
@app.route("/dashboard")
def dashboard():
    # ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
    
# API ‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏≥
@app.route("/tokenize", methods=["POST"])
def tokenize_text():
    # API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
```

### 2. API Endpoints

```bash
# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
python app.py

# ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå
http://localhost:5000

# ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô API ‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏≥
curl -X POST http://localhost:5000/tokenize \
  -H "Content-Type: application/json" \
  -d '{"lyrics": "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏≥"}'

# ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏û‡∏•‡∏á
curl -X POST http://localhost:5000/search \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d 'query=‡πÄ‡∏®‡∏£‡πâ‡∏≤ ‚Üí ‡∏´‡∏ß‡∏±‡∏á'
```

### 3. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤

```bash
# ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies
pip install -r requirements.txt

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°
echo "YOUTUBE_API_KEY=your_youtube_api_key_here" > .env

# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
python db_setup.py

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô
python app.py
```

## ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### 1. ‡∏™‡∏Å‡∏µ‡∏°‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• SQLite

```sql
-- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏û‡∏•‡∏á‡∏´‡∏•‡∏±‡∏Å
CREATE TABLE songs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT,
    youtube_link TEXT,
    description TEXT,
    tags TEXT,
    upload_date TEXT,
    view_count INTEGER,
    like_count INTEGER,
    lyrics TEXT,
    image_path TEXT,
    graph_html TEXT  -- ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• Plotly ‡∏ó‡∏µ‡πà‡πÅ‡∏Ñ‡∏ä‡πÑ‡∏ß‡πâ
);

-- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏•‡∏á
CREATE TABLE segments (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    song_id INTEGER,
    segment_order INTEGER,
    text TEXT,
    emotion TEXT,  -- ‡∏õ‡πâ‡∏≤‡∏¢‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (sad, happy, ‡∏Ø‡∏•‡∏Ø)
    FOREIGN KEY(song_id) REFERENCES songs(id)
);
```

### 2. ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°

```python
def db_query(query, args=(), fetch=False):
    conn = None
    try:
        conn = sqlite3.connect("songs.db")
        cur = conn.cursor()
        cur.execute(query, args)
        rows = cur.fetchall() if fetch else None
        conn.commit()
        return rows
    except Exception as e:
        if conn:
            conn.rollback()
        raise e
    finally:
        if conn:
            conn.close()

# ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏û‡∏•‡∏á‡πÅ‡∏ö‡∏ö‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
try:
    conn = sqlite3.connect("songs.db")
    cur = conn.cursor()
    
    try:
        # ‡πÄ‡∏£‡∏¥‡πà‡∏° transaction
        cur.execute("BEGIN TRANSACTION")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏•‡∏á
        cur.execute("""
            INSERT INTO songs (title,youtube_link,lyrics)
            VALUES (?,?,?)
        """, (title, link, lyrics))
        
        song_id = cur.lastrowid
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° segments
        for i, seg in enumerate(segments):
            cur.execute("""
                INSERT INTO segments (song_id,segment_order,text,emotion) 
                VALUES (?,?,?,?)""", (song_id, i, seg, emotion))
        
        # commit transaction
        conn.commit()
        
    except Exception as e:
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î rollback
        conn.rollback()
        raise e
    finally:
        # ‡∏õ‡∏¥‡∏î connection
        conn.close()
        
except Exception as e:
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ‡πÉ‡∏´‡πâ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏•‡∏á‡∏ó‡∏¥‡πâ‡∏á
    db_query("DELETE FROM segments WHERE song_id=?", (song_id,))
    db_query("DELETE FROM songs WHERE id=?", (song_id,))
```

### 3. ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå

```python
def get_emotion_color(emotion):
    """
    ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
    """
    emotion_colors = {
        'sad': 'bg-blue-100 text-blue-800 border-blue-200',
        'lonely': 'bg-purple-100 text-purple-800 border-purple-200',
        'hope': 'bg-green-100 text-green-800 border-green-200',
        'happy': 'bg-yellow-100 text-yellow-800 border-yellow-200',
        'excited': 'bg-red-100 text-red-800 border-red-200',
        'calm': 'bg-indigo-100 text-indigo-800 border-indigo-200',
        'angry': 'bg-orange-100 text-orange-800 border-orange-200',
        'neutral': 'bg-gray-100 text-gray-600 border-gray-300',
        'unknown': 'bg-gray-100 text-gray-500 border-gray-300'
    }
    return emotion_colors.get(emotion.lower(), 'bg-gray-100 text-gray-500 border-gray-300')

def get_emotion_icon(emotion):
    """
    ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
    """
    emotion_icons = {
        'sad': 'üíô',
        'lonely': 'üíú',
        'hope': 'üíö',
        'happy': 'üíõ',
        'excited': '‚ù§Ô∏è',
        'calm': 'üîµ',
        'angry': 'üß°',
        'neutral': '‚ö™',
        'unknown': '‚ùì'
    }
    return emotion_icons.get(emotion.lower(), '‚ùì')
```

## ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ-‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö

### 1. ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ

#### ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á
- **‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• BART**: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡∏°‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ‡∏ö‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà
- **‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡∏£‡∏≠‡∏á**: ‡∏°‡∏µ lexicon ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏≠‡∏á
- **‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ**: ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö threshold ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

#### ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤
- **‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©**: ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏ú‡∏™‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ
- **‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏õ‡∏™‡∏≠‡∏á‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á**: ‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- **‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏≥‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞**: ‡πÉ‡∏ä‡πâ PyThaiNLP ‡πÅ‡∏•‡∏∞ NLTK

#### ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°
- **‡∏Å‡∏£‡∏≤‡∏ü Plotly**: ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏≠‡∏Ñ‡∏ó‡∏µ‡∏ü‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á
- **‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏µ‡πÅ‡∏•‡∏∞‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô**: ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á
- **‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°**: ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥

#### ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞
- **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö**: ‡∏•‡∏π‡∏Å‡∏®‡∏£, ‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥, ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
- **‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà**: LCS, soft subsequence matching
- **‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢**: ‡πÉ‡∏ä‡πâ FAISS ‡πÅ‡∏•‡∏∞ sentence transformers

#### ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
- **SQLite**: ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ö‡∏≤‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡πá‡∏ß
- **‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ cache**: ‡πÄ‡∏Å‡πá‡∏ö‡∏Å‡∏£‡∏≤‡∏ü HTML ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß
- **Transaction safety**: ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢

### 2. ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢

#### ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
- **‡πÇ‡∏°‡πÄ‡∏î‡∏• BART**: ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏ô‡∏≤‡∏ô
- **‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á**: ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å
- **‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•**: ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ô‡∏≤‡∏ô

#### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£
- **RAM usage**: ‡πÇ‡∏°‡πÄ‡∏î‡∏• BART ‡πÉ‡∏ä‡πâ RAM ‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏™‡∏π‡∏á
- **GPU dependency**: ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ GPU ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏î‡∏µ
- **Storage**: ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• embeddings

#### ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏†‡∏≤‡∏©‡∏≤
- **‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡πÜ**: ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
- **‡∏™‡∏≥‡πÄ‡∏ô‡∏µ‡∏¢‡∏á**: ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏û‡∏π‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏≥‡πÄ‡∏ô‡∏µ‡∏¢‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ
- **‡∏ö‡∏£‡∏¥‡∏ö‡∏ó**: ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏≠‡∏≤‡∏à‡∏à‡∏≥‡∏Å‡∏±‡∏î

#### ‡∏Å‡∏≤‡∏£‡∏û‡∏∂‡πà‡∏á‡∏û‡∏≤ API
- **YouTube API key**: ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ API key ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
- **Rate limiting**: ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ
- **‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢**: ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô limit ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢

#### ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏Å‡∏±‡∏î
- **‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á**: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
- **‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°**: ‡∏≠‡∏≤‡∏à‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡∏Å‡∏£‡∏ì‡∏µ
- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢**: ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏•‡∏á

## ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡∏∞‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï

### 1. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

#### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á
```python
# ‡πÉ‡∏ä‡πâ DistilBART ‡πÅ‡∏ó‡∏ô BART
ZS_MODEL = "distilbart-mnli-12-3"

# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ T5 ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤
from transformers import T5ForConditionalGeneration, T5Tokenizer

model = T5ForConditionalGeneration.from_pretrained("t5-small")
tokenizer = T5Tokenizer.from_pretrained("t5-small")
```

#### ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡πâ‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
```python
# Redis ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö caching
import redis
r = redis.Redis(host='localhost', port=6379, db=0)

def detect_emotion_cached(text):
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö cache ‡∏Å‡πà‡∏≠‡∏ô
    cache_key = f"emotion:{hash(text)}"
    cached_result = r.get(cache_key)
    
    if cached_result:
        return cached_result.decode()
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô cache ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÉ‡∏´‡∏°‡πà
    result = detect_emotion(text)
    r.setex(cache_key, 3600, result)  # Cache 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
    
    return result
```

#### ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö Asynchronous
```python
# ‡πÉ‡∏ä‡πâ Celery ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö background tasks
from celery import Celery

celery_app = Celery('emotion_app', broker='redis://localhost:6379')

@celery_app.task
def analyze_song_async(song_id, lyrics):
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ô background
    segments = preprocess_lyrics(lyrics)
    emotions = [detect_emotion(seg) for seg in segments]
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    update_song_emotions(song_id, emotions)
    
    return emotions

# ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
analyze_song_async.delay(song_id, lyrics)
```

### 2. ‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ

#### ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á
```python
import librosa
import numpy as np

def analyze_audio_emotion(audio_file):
    # ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    y, sr = librosa.load(audio_file)
    
    # ‡∏™‡∏Å‡∏±‡∏î features
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
    spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå emotion ‡∏à‡∏≤‡∏Å features ‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    emotion = classify_audio_emotion(mfccs, spectral_centroids)
    
    return emotion

def classify_audio_emotion(features):
    # ‡πÉ‡∏ä‡πâ ML model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    pass
```

#### ‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏•‡∏á
```python
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class MusicRecommendationSystem:
    def __init__(self):
        self.user_emotion_profiles = {}
        self.song_emotion_features = {}
    
    def add_user_interaction(self, user_id, song_id, emotion_score):
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
        if user_id not in self.user_emotion_profiles:
            self.user_emotion_profiles[user_id] = {}
        
        self.user_emotion_profiles[user_id][song_id] = emotion_score
    
    def recommend_songs(self, user_id, target_emotion, n_recommendations=10):
        # ‡∏´‡∏≤‡πÄ‡∏û‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢
        user_profile = self.user_emotion_profiles.get(user_id, {})
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢
        similarities = []
        for song_id, features in self.song_emotion_features.items():
            similarity = self.calculate_emotion_similarity(
                target_emotion, features
            )
            similarities.append((song_id, similarity))
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        return similarities[:n_recommendations]
```

#### ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
```python
class UserEmotionAnalyzer:
    def __init__(self):
        self.user_listening_history = {}
        self.emotion_preferences = {}
    
    def track_user_emotion_preference(self, user_id, song_emotions):
        # ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏≠‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
        if user_id not in self.emotion_preferences:
            self.emotion_preferences[user_id] = {}
        
        for emotion in song_emotions:
            self.emotion_preferences[user_id][emotion] = \
                self.emotion_preferences[user_id].get(emotion, 0) + 1
    
    def get_user_emotion_profile(self, user_id):
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
        preferences = self.emotion_preferences.get(user_id, {})
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå
        total = sum(preferences.values())
        if total == 0:
            return {}
        
        return {
            emotion: count/total 
            for emotion, count in preferences.items()
        }
    
    def suggest_emotion_based_playlist(self, user_id):
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏û‡∏•‡∏¢‡πå‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏≠‡∏ö
        profile = self.get_user_emotion_profile(user_id)
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏û‡∏•‡∏á‡∏ï‡∏≤‡∏°‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå
        recommended_songs = []
        for emotion, percentage in profile.items():
            if percentage > 0.3:  # ‡∏ñ‡πâ‡∏≤‡∏ä‡∏≠‡∏ö‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 30%
                songs = get_songs_by_emotion(emotion)
                recommended_songs.extend(songs[:5])
        
        return recommended_songs
```

### 3. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏ü‡∏ã

#### Responsive Design
```css
/* CSS ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ö‡∏ô‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠ */
.emotion-chart {
    width: 100%;
    height: 300px;
    margin: 10px 0;
}

@media (max-width: 768px) {
    .emotion-chart {
        height: 250px;
        font-size: 12px;
    }
    
    .emotion-controls {
        flex-direction: column;
        gap: 10px;
    }
}

@media (max-width: 480px) {
    .emotion-chart {
        height: 200px;
        padding: 5px;
    }
}
```

#### ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö Real-time
```python
from flask_socketio import SocketIO, emit
import eventlet

socketio = SocketIO(app, cors_allowed_origins="*")

@app.route('/stream_analysis/<int:song_id>')
def stream_analysis(song_id):
    socketio.emit('analysis_started', {'song_id': song_id})
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏µ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
    segments = preprocess_lyrics(lyrics)
    for i, seg in enumerate(segments):
        emotion = detect_emotion(seg)
        socketio.emit('segment_analyzed', {
            'song_id': song_id,
            'segment_index': i,
            'emotion': emotion,
            'progress': (i+1)/len(segments)
        })
        time.sleep(0.5)  # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    
    socketio.emit('analysis_completed', {'song_id': song_id})
```

#### ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
```python
import pandas as pd
from flask import send_file
import io

@app.route('/export/song/<int:song_id>/<format>')
def export_song_data(song_id, format):
    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏•‡∏á
    song_data = get_song_with_segments(song_id)
    
    if format == 'excel':
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Excel
        df = pd.DataFrame(song_data['segments'])
        output = io.BytesIO()
        
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Song Analysis', index=False)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
            summary = create_emotion_summary(song_data['emotions'])
            summary_df = pd.DataFrame([summary])
            summary_df.to_excel(writer, sheet_name='Summary', index=False)
        
        output.seek(0)
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=f'song_{song_id}_analysis.xlsx'
        )
    
    elif format == 'pdf':
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á PDF
        pdf_buffer = create_analysis_pdf(song_data)
        return send_file(
            pdf_buffer,
            mimetype='application/pdf',
            as_attachment=True,
            download_name=f'song_{song_id}_analysis.pdf'
        )
```

### 4. ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á

#### ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
```python
def compare_songs_emotion(song_ids):
    """
    ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏•‡∏á‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏û‡∏•‡∏á
    """
    songs_data = []
    for song_id in song_ids:
        song = get_song_with_segments(song_id)
        songs_data.append({
            'id': song_id,
            'title': song['title'],
            'emotions': song['emotions'],
            'overall_emotion': calculate_overall_emotion(song['emotions'])
        })
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á comparison chart
    comparison_data = []
    for song in songs_data:
        for i, emotion in enumerate(song['emotions']):
            comparison_data.append({
                'song': song['title'],
                'step': i,
                'emotion': emotion
            })
    
    df = pd.DataFrame(comparison_data)
    fig = px.line(
        df, x='step', y='emotion', color='song',
        title='Emotion Trajectory Comparison',
        markers=True
    )
    
    return fig.to_html(full_html=False)
```

#### ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏û‡∏•‡∏¢‡πå‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
```python
def create_emotion_based_playlist(target_emotion_sequence, target_duration=30):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏û‡∏•‡∏¢‡πå‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    """
    playlist = []
    current_duration = 0
    
    for emotion in target_emotion_sequence:
        # ‡∏´‡∏≤‡πÄ‡∏û‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
        candidate_songs = get_songs_by_emotion(emotion)
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏¥‡∏¢‡∏°, ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û)
        candidate_songs.sort(key=lambda x: (x['like_count'], x['view_count']), reverse=True)
        
        for song in candidate_songs:
            song_duration = get_song_duration(song['youtube_link'])
            if current_duration + song_duration <= target_duration:
                playlist.append(song)
                current_duration += song_duration
                break
    
    return playlist
```

#### ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å
```python
def analyze_listener_emotion(lyrics, audio_features=None):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡πà‡∏≤‡∏ú‡∏π‡πâ‡∏ü‡∏±‡∏á‡∏à‡∏∞‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ü‡∏±‡∏á‡πÄ‡∏û‡∏•‡∏á
    """
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á
    lyrical_emotions = detect_emotion_progression(lyrics)
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å features ‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    audio_emotions = []
    if audio_features:
        audio_emotions = classify_audio_emotion(audio_features)
    
    # ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    listener_response = {
        'expected_emotions': lyrical_emotions,
        'audio_influence': audio_emotions,
        'intensity_prediction': predict_emotion_intensity(lyrics),
        'emotional_arc': create_emotional_arc(lyrical_emotions),
        'listener_recommendations': generate_listener_tips(lyrical_emotions)
    }
    
    return listener_response

def generate_listener_tips(emotions):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ü‡∏±‡∏á
    """
    tips = []
    
    if 'sad' in emotions:
        tips.append("‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å")
    
    if 'excited' in emotions:
        tips.append("‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏≤‡∏£‡πå‡∏ï‡∏µ‡πâ")
    
    if 'calm' in emotions:
        tips.append("‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡∏™‡∏°‡∏≤‡∏ò‡∏¥")
    
    return tips
```

### 5. ‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤

#### ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏≠‡πÄ‡∏ä‡∏µ‡∏¢‡∏≠‡∏∑‡πà‡∏ô‡πÜ
```python
# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏à‡∏µ‡∏ô
from transformers import BertTokenizer, BertForSequenceClassification

chinese_tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')
chinese_model = BertForSequenceClassification.from_pretrained('bert-base-chinese')

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô
japanese_tokenizer = BertTokenizer.from_pretrained('bert-base-japanese')
japanese_model = BertForSequenceClassification.from_pretrained('bert-base-japanese')

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏Å‡∏≤‡∏´‡∏•‡∏µ
korean_tokenizer = BertTokenizer.from_pretrained('kykim/bert-kor-base')
korean_model = BertForSequenceClassification.from_pretrained('kykim/bert-kor-base')

def detect_emotion_multilingual(text, language='thai'):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤
    """
    if language == 'chinese':
        return detect_emotion_chinese(text)
    elif language == 'japanese':
        return detect_emotion_japanese(text)
    elif language == 'korean':
        return detect_emotion_korean(text)
    else:
        return detect_emotion(text)
```

#### ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
```python
from googletrans import Translator

translator = Translator()

def translate_lyrics_for_analysis(lyrics, target_lang='en'):
    """
    ‡πÅ‡∏õ‡∏•‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    """
    try:
        # ‡πÅ‡∏¢‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ
        sections = preprocess_lyrics(lyrics)
        translated_sections = []
        
        for section in sections:
            # ‡πÅ‡∏õ‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
            translated = translator.translate(section, dest=target_lang)
            translated_sections.append(translated.text)
        
        return ' '.join(translated_sections)
    
    except Exception as e:
        print(f"Translation error: {e}")
        return lyrics  # ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö

def analyze_with_auto_translation(lyrics, original_lang='auto'):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
    """
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏†‡∏≤‡∏©‡∏≤
    detected_lang = translator.detect(lyrics).lang
    
    if detected_lang != 'en':
        # ‡πÅ‡∏õ‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        english_lyrics = translate_lyrics_for_analysis(lyrics, 'en')
        emotions = detect_emotion_progression(english_lyrics)
        
        # ‡πÅ‡∏õ‡∏•‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        return {
            'original_language': detected_lang,
            'emotions': emotions,
            'translated_for_analysis': english_lyrics
        }
    else:
        return {
            'original_language': 'en',
            'emotions': detect_emotion_progression(lyrics),
            'translated_for_analysis': lyrics
        }
```

#### ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
```python
from langdetect import detect, detect_langs

def detect_language_smart(text):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à
    """
    try:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ
        probabilities = detect_langs(text)
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
        best_lang = max(probabilities, key=lambda x: x.prob)
        
        return {
            'language': best_lang.lang,
            'confidence': best_lang.prob
        }
    
    except Exception:
        return {
            'language': 'unknown',
            'confidence': 0.0
        }

def auto_language_processing(text):
    """
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ
    """
    lang_info = detect_language_smart(text)
    
    if lang_info['confidence'] > 0.8:
        return {
            'detected_language': lang_info['language'],
            'processing_method': get_processing_method(lang_info['language']),
            'confidence': lang_info['confidence']
        }
    else:
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏ú‡∏™‡∏°
        return {
            'detected_language': 'mixed',
            'processing_method': 'mixed_language',
            'confidence': lang_info['confidence']
        }
```

### 6. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö

#### Microservices Architecture
```python
# emotion_service.py - Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
from flask import Flask, request, jsonify

emotion_app = Flask(__name__)

@emotion_app.route('/detect_emotion', methods=['POST'])
def detect_emotion_endpoint():
    data = request.json
    text = data.get('text', '')
    emotion = detect_emotion(text)
    return jsonify({'emotion': emotion})

@emotion_app.route('/batch_detect', methods=['POST'])
def batch_detect_emotion_endpoint():
    texts = request.json.get('texts', [])
    emotions = [detect_emotion(text) for text in texts]
    return jsonify({'emotions': emotions})

# search_service.py - Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
search_app = Flask(__name__)

@search_app.route('/search', methods=['POST'])
def search_endpoint():
    query = request.json.get('query', '')
    results = perform_advanced_search(query)
    return jsonify({'results': results})

# music_service.py - Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏•‡∏á
music_app = Flask(__name__)

@music_app.route('/add_song', methods=['POST'])
def add_song_endpoint():
    song_data = request.json
    song_id = add_song_to_database(song_data)
    return jsonify({'song_id': song_id})

@music_app.route('/get_song/<int:song_id>')
def get_song_endpoint(song_id):
    song_data = get_song_data(song_id)
    return jsonify(song_data)
```

#### Docker Containerization
```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 5000

CMD ["python", "app.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  emotion-app:
    build: .
    ports:
      - "5000:5000"
    environment:
      - YOUTUBE_API_KEY=${YOUTUBE_API_KEY}
      - DATABASE_URL=sqlite:///songs.db
    volumes:
      - ./data:/app/data
    depends_on:
      - redis
      - postgres

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"

  postgres:
    image: postgres:13
    environment:
      - POSTGRES_DB=emotion_music
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - emotion-app

volumes:
  postgres_data:
```

#### Cloud Integration
```python
# cloud_storage.py
import boto3
from google.cloud import storage
import os

class CloudStorageManager:
    def __init__(self, provider='aws'):
        self.provider = provider
        
        if provider == 'aws':
            self.s3_client = boto3.client('s3')
            self.bucket_name = os.getenv('S3_BUCKET_NAME')
        elif provider == 'gcp':
            self.storage_client = storage.Client()
            self.bucket_name = os.getenv('GCS_BUCKET_NAME')
    
    def upload_analysis_result(self, song_id, result_data):
        """
        ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á cloud storage
        """
        filename = f"analysis/{song_id}/result.json"
        
        if self.provider == 'aws':
            self.s3_client.put_object(
                Bucket=self.bucket_name,
                Key=filename,
                Body=json.dumps(result_data),
                ContentType='application/json'
            )
        elif self.provider == 'gcp':
            bucket = self.storage_client.bucket(self.bucket_name)
            blob = bucket.blob(filename)
            blob.upload_from_string(json.dumps(result_data))
    
    def download_audio_for_analysis(self, audio_url, local_path):
        """
        ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        """
        if self.provider == 'aws':
            # ‡πÉ‡∏ä‡πâ S3 presigned URL
            response = requests.get(audio_url)
            with open(local_path, 'wb') as f:
                f.write(response.content)
        elif self.provider == 'gcp':
            # ‡πÉ‡∏ä‡πâ GCS signed URL
            response = requests.get(audio_url)
            with open(local_path, 'wb') as f:
                f.write(response.content)
```

```python
# cloud_ml.py
import tensorflow as tf
import torch
from transformers import pipeline

class CloudMLService:
    def __init__(self, provider='aws'):
        self.provider = provider
        
        if provider == 'aws':
            self.sagemaker_client = boto3.client('sagemaker')
            self.endpoint_name = os.getenv('SAGEMAKER_ENDPOINT')
        elif provider == 'gcp':
            self.ai_platform = discovery.build('ml', 'v1')
            self.model_name = os.getenv('GCP_MODEL_NAME')
    
    def batch_emotion_analysis(self, lyrics_batch):
        """
        ‡πÉ‡∏ä‡πâ ML service ‡πÉ‡∏ô cloud ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å
        """
        if self.provider == 'aws':
            # ‡πÉ‡∏ä‡πâ SageMaker batch transform
            response = self.sagemaker_client.transform_job(
                TransformJobName=f"emotion-analysis-{int(time.time())}",
                ModelName=self.endpoint_name,
                TransformInput={
                    'DataSource': {
                        'S3DataSource': {
                            'S3DataType': 'S3Prefix',
                            'S3Uri': 's3://my-bucket/input-data/'
                        }
                    }
                },
                TransformOutput={
                    'S3OutputPath': 's3://my-bucket/output-data/'
                }
            )
            return response['TransformJobArn']
        
        elif provider == 'gcp':
            # ‡πÉ‡∏ä‡πâ AI Platform Prediction
            instances = [{"lyrics": lyrics} for lyrics in lyrics_batch]
            response = self.ai_platform.projects().predict(
                name=self.model_name,
                body={'instances': instances}
            ).execute()
            return response['predictions']
```

## ‡∏™‡∏£‡∏∏‡∏õ

‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Emotion Music App ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ Machine Learning ‡πÅ‡∏•‡∏∞ Natural Language Processing ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏á ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°

### ‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô‡∏´‡∏•‡∏±‡∏Å
- **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á**: ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• BART ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡∏£‡∏≠‡∏á
- **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤**: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
- **‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°**: ‡πÉ‡∏ä‡πâ Plotly ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≤‡∏ü‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏≠‡∏Ñ‡∏ó‡∏µ‡∏ü
- **‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
- **‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û**: ‡πÉ‡∏ä‡πâ SQLite ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ cache

### ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï
- **‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û**: ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á, ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ cache, asynchronous processing
- **‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ**: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á, ‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥, ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
- **‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏ü‡∏ã**: responsive design, real-time updates, data export
- **‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á**: ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏û‡∏•‡∏á, ‡πÄ‡∏û‡∏•‡∏¢‡πå‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥, ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å
- **‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤**: ‡∏à‡∏µ‡∏ô, ‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô, ‡πÄ‡∏Å‡∏≤‡∏´‡∏•‡∏µ, ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- **‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö**: microservices, Docker, cloud integration

‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ô‡∏µ‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÑ‡∏õ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ï‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÑ‡∏î‡πâ ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡∏®‡∏±‡∏Å‡∏¢‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï